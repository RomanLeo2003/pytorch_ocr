{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torchvision\nimport random\nfrom PIL import Image\nimport cv2\nimport os\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-12-13T15:18:00.327289Z","iopub.execute_input":"2022-12-13T15:18:00.328170Z","iopub.status.idle":"2022-12-13T15:18:00.730195Z","shell.execute_reply.started":"2022-12-13T15:18:00.328129Z","shell.execute_reply":"2022-12-13T15:18:00.729101Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate jiwer\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:00.990795Z","iopub.execute_input":"2022-12-13T15:18:00.991416Z","iopub.status.idle":"2022-12-13T15:18:11.568437Z","shell.execute_reply.started":"2022-12-13T15:18:00.991381Z","shell.execute_reply":"2022-12-13T15:18:11.567069Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: evaluate in /opt/conda/lib/python3.7/site-packages (0.4.0)\nRequirement already satisfied: jiwer in /opt/conda/lib/python3.7/site-packages (2.5.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.10.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.13.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.13)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2022.8.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.0.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.5.1)\nRequirement already satisfied: levenshtein==0.20.2 in /opt/conda/lib/python3.7/site-packages (from jiwer) (0.20.2)\nRequirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from levenshtein==0.20.2->jiwer) (2.11.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (8.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2022.1)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.2)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"random.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)\nnp.random.seed(42)\ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:11.570800Z","iopub.execute_input":"2022-12-13T15:18:11.571262Z","iopub.status.idle":"2022-12-13T15:18:11.581601Z","shell.execute_reply.started":"2022-12-13T15:18:11.571219Z","shell.execute_reply":"2022-12-13T15:18:11.580150Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#  **Load dataset**","metadata":{}},{"cell_type":"markdown","source":"### Tokenize our labels","metadata":{}},{"cell_type":"code","source":"def exec_label(path):\n    return path[path.find('-') + 1:path.find('.')]\n\ninput_dir_train = '/kaggle/input/labtinkoff/CCPD2019-dl1/train'\n\nnumbers = [exec_label(path) for  path in os.listdir(input_dir_train)]","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:11.583265Z","iopub.execute_input":"2022-12-13T15:18:11.583615Z","iopub.status.idle":"2022-12-13T15:18:12.654076Z","shell.execute_reply.started":"2022-12-13T15:18:11.583579Z","shell.execute_reply":"2022-12-13T15:18:12.653079Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"seq = ''\nfor number in numbers:\n    seq += number\nalphabet = ''\nfor symbol in sorted(set(seq)):\n    alphabet += symbol\nalphabet    ","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:12.658656Z","iopub.execute_input":"2022-12-13T15:18:12.658980Z","iopub.status.idle":"2022-12-13T15:18:12.725417Z","shell.execute_reply.started":"2022-12-13T15:18:12.658955Z","shell.execute_reply":"2022-12-13T15:18:12.724571Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'0123456789ABCDEFGHJKLMNOPQRSTUVWXYZ云京冀吉宁川新晋桂沪津浙渝湘琼甘皖粤苏蒙藏豫贵赣辽鄂闽陕青鲁黑'"},"metadata":{}}]},{"cell_type":"code","source":"OOV_TOKEN = '<OOV>'\nCTC_BLANK = '<BLANK>'\n\n\ndef get_char_map(alphabet):\n    \"\"\"Make from string alphabet character2int dict.\n    Add BLANK char fro CTC loss and OOV char for out of vocabulary symbols.\"\"\"\n    char_map = {value: idx + 2 for (idx, value) in enumerate(alphabet)}\n    char_map[CTC_BLANK] = 0\n    char_map[OOV_TOKEN] = 1\n    return char_map\n\n\nclass Tokenizer:\n    \"\"\"Class for encoding and decoding string word to sequence of int\n    (and vice versa) using alphabet.\"\"\"\n\n    def __init__(self, alphabet):\n        self.char_map = get_char_map(alphabet)\n        self.rev_char_map = {val: key for key, val in self.char_map.items()}\n\n    def encode(self, word_list):\n        \"\"\"Returns a list of encoded words (int).\"\"\"\n        enc_words = []\n        for word in word_list:\n            enc_words.append(\n                [self.char_map[char] if char in self.char_map\n                 else self.char_map[OOV_TOKEN]\n                 for char in word]\n            )\n        return enc_words\n\n    def get_num_chars(self):\n        return len(self.char_map)\n\n    def decode(self, enc_word_list):\n        \"\"\"Returns a list of words (str) after removing blanks and collapsing\n        repeating characters. Also skip out of vocabulary token.\"\"\"\n        dec_words = []\n        for word in enc_word_list:\n            word_chars = ''\n            for idx, char_enc in enumerate(word):\n                # skip if blank symbol, oov token or repeated characters\n                if (\n                    char_enc != self.char_map[OOV_TOKEN]\n                    and char_enc != self.char_map[CTC_BLANK]\n                    # idx > 0 to avoid selecting [-1] item\n                    and not (idx > 0 and char_enc == word[idx - 1])\n                ):\n                    word_chars += self.rev_char_map[char_enc]\n            dec_words.append(word_chars)\n        return dec_words","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:12.726638Z","iopub.execute_input":"2022-12-13T15:18:12.726904Z","iopub.status.idle":"2022-12-13T15:18:12.738049Z","shell.execute_reply.started":"2022-12-13T15:18:12.726865Z","shell.execute_reply":"2022-12-13T15:18:12.736930Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(alphabet)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:12.739473Z","iopub.execute_input":"2022-12-13T15:18:12.739823Z","iopub.status.idle":"2022-12-13T15:18:12.770345Z","shell.execute_reply.started":"2022-12-13T15:18:12.739787Z","shell.execute_reply":"2022-12-13T15:18:12.769017Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Laba_dataset(torch.utils.data.Dataset):\n    def __init__(self, root, tokenizer, transform=None):\n        self.root = root\n        self.transform = transform\n        self.tokenizer = tokenizer\n        self.img_paths = [os.path.join(self.root, img_path) for img_path in os.listdir(self.root)]\n        self.labels = [exec_label(path) for path in os.listdir(self.root)]\n        self.enc_labels = self.tokenizer.encode(self.labels)\n    \n    def __getitem__(self, ind):\n        img = cv2.imread(self.img_paths[ind], cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (128, 32)) # resize\n        if self.transform is not None:\n            img = self.transform(img) / 255\n        else:\n            img = torch.from_numpy(img).float() / 255\n        return (img.unsqueeze(0), torch.LongTensor(self.enc_labels[ind]), self.labels[ind])\n\n    def __len__(self):\n        return len(self.img_paths)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:12.772060Z","iopub.execute_input":"2022-12-13T15:18:12.772425Z","iopub.status.idle":"2022-12-13T15:18:12.791724Z","shell.execute_reply.started":"2022-12-13T15:18:12.772364Z","shell.execute_reply":"2022-12-13T15:18:12.790935Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    images, enc_texts, texts = zip(*batch)\n    images = torch.stack(images, 0)\n    enc_pad_texts = torch.nn.utils.rnn.pad_sequence(enc_texts, batch_first=True, padding_value=0)\n    return images, enc_pad_texts, texts","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:12.792966Z","iopub.execute_input":"2022-12-13T15:18:12.793394Z","iopub.status.idle":"2022-12-13T15:18:12.804705Z","shell.execute_reply.started":"2022-12-13T15:18:12.793367Z","shell.execute_reply":"2022-12-13T15:18:12.803610Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nbatch_size = 128\ntransform = torchvision.transforms.Compose([\n    torchvision.transforms.ToPILImage(),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.RandomRotation(15),\n    torchvision.transforms.ToTensor()\n        ])\ndataset_full = Laba_dataset(input_dir_train, tokenizer)\n# split full dataset\ntrain_idx, valid_idx = train_test_split(list(range(len(dataset_full))), train_size=0.9)\ndataset = {\n    'train': torch.utils.data.Subset(dataset_full, train_idx),\n    'valid': torch.utils.data.Subset(dataset_full, valid_idx)\n}\n\ndataset_size = {ds: len(dataset[ds]) for ds in ['train', 'valid']}\n\ndataloader = {\n    'train': torch.utils.data.DataLoader(\n        dataset=dataset['train'], batch_size=batch_size, shuffle=True, collate_fn=collate_fn\n    ),\n    'valid': torch.utils.data.DataLoader(\n        dataset=dataset['valid'], batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n    ),\n}","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:12.806075Z","iopub.execute_input":"2022-12-13T15:18:12.806337Z","iopub.status.idle":"2022-12-13T15:18:14.094269Z","shell.execute_reply.started":"2022-12-13T15:18:12.806314Z","shell.execute_reply":"2022-12-13T15:18:14.093021Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"input_dir_test = '/kaggle/input/labtinkoff/CCPD2019-dl1/test'\nbatch_size = 128\ntransform_test = torchvision.transforms.Compose([\n            torchvision.transforms.Normalize(mean=(0.406), std=(0.225))\n        ])\ndataset_test = Laba_dataset(input_dir_test, tokenizer)\ndataloader_test = torch.utils.data.DataLoader(\n        dataset=dataset_test, batch_size=batch_size, shuffle=False, collate_fn=collate_fn\n    )","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.097911Z","iopub.execute_input":"2022-12-13T15:18:14.098255Z","iopub.status.idle":"2022-12-13T15:18:14.272075Z","shell.execute_reply.started":"2022-12-13T15:18:14.098226Z","shell.execute_reply":"2022-12-13T15:18:14.270925Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"next(iter(dataloader['train']))[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.273783Z","iopub.execute_input":"2022-12-13T15:18:14.274168Z","iopub.status.idle":"2022-12-13T15:18:14.833748Z","shell.execute_reply.started":"2022-12-13T15:18:14.274134Z","shell.execute_reply":"2022-12-13T15:18:14.832940Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 1, 32, 128])"},"metadata":{}}]},{"cell_type":"code","source":"img = torchvision.transforms.ToPILImage()(dataset_full[0][0])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.834911Z","iopub.execute_input":"2022-12-13T15:18:14.835204Z","iopub.status.idle":"2022-12-13T15:18:14.843893Z","shell.execute_reply.started":"2022-12-13T15:18:14.835178Z","shell.execute_reply":"2022-12-13T15:18:14.843110Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"img","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.844798Z","iopub.execute_input":"2022-12-13T15:18:14.845527Z","iopub.status.idle":"2022-12-13T15:18:14.863641Z","shell.execute_reply.started":"2022-12-13T15:18:14.845502Z","shell.execute_reply":"2022-12-13T15:18:14.862422Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=L size=128x32>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### Make some augmentation","metadata":{}},{"cell_type":"markdown","source":"## Define model","metadata":{}},{"cell_type":"code","source":"from torch import nn","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.864805Z","iopub.execute_input":"2022-12-13T15:18:14.865105Z","iopub.status.idle":"2022-12-13T15:18:14.869938Z","shell.execute_reply.started":"2022-12-13T15:18:14.865080Z","shell.execute_reply":"2022-12-13T15:18:14.868416Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class ResNetBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=0, dropout=0.1):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.LeakyReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.downsample = None\n        if in_channels != out_channels:\n            self.downsample = nn.Conv2d(in_channels, out_channels, 1, stride=2)\n        \n    def forward(self, x, identity=True):\n        out = self.dropout(self.bn(self.conv(x)))\n        if identity:\n            if self.downsample is not None:\n                x = self.downsample(x)\n            return self.relu(out + x)\n        else: \n            return self.relu(out)\n    \nclass CNN(nn.Module):\n    def __init__(self, in_channels=1, num_layers=2, dropout=0.1):\n        super().__init__()\n        self.start = ResNetBlock(1, 64, 7, 1, 0, 0.0)\n        self.maxpool = nn.MaxPool2d(3, 2, 1)\n        self.blocks1 = nn.ModuleList([ResNetBlock(64, 64, padding=1) for _ in range(num_layers)])\n        self.blocks2 = nn.ModuleList([ResNetBlock(64, 128, padding=1, stride=2)] + [ResNetBlock(128, 128, padding=1) for _ in range(num_layers)])\n        self.blocks3 = nn.ModuleList([ResNetBlock(128, 256, padding=1, stride=2)] + [ResNetBlock(256, 256, padding=1) for _ in range(num_layers)])\n        self.blocks4 = nn.ModuleList([ResNetBlock(256, 512, padding=1, stride=2)] + [ResNetBlock(512, 512, padding=1) for _ in range(num_layers)])\n        self.blocks5 = nn.ModuleList([ResNetBlock(512, 1024, padding=1, stride=2)] + [ResNetBlock(1024, 1024, padding=1) for _ in range(num_layers)])\n        \n        \n    def forward(self, x):\n        out = self.maxpool(self.start(x, identity=False))\n        for layer in self.blocks1:\n            out = layer(out)\n            \n        for layer in self.blocks2:\n            out = layer(out)\n            \n        for layer in self.blocks3:\n            out = layer(out)\n            \n        for layer in self.blocks4:\n            out = layer(out)\n            \n        for layer in self.blocks5:\n            out = layer(out)\n            \n        return out\n\nclass BiLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, dropout=0.1):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_size, hidden_size, num_layers,\n            dropout=dropout, batch_first=True, bidirectional=True)\n\n    def forward(self, x):\n        out, _ = self.lstm(x)\n        return out\n\n\nclass CRNN(nn.Module):\n    def __init__(\n        self, number_class_symbols, time_feature_count=256, lstm_hidden=256,\n        lstm_len=3,\n    ):\n        super().__init__()\n        self.feature_extractor = CNN()\n        self.avg_pool = nn.AdaptiveAvgPool2d(\n            (time_feature_count, time_feature_count))\n        self.bilstm = BiLSTM(time_feature_count, lstm_hidden, lstm_len)\n        self.classifier = nn.Sequential(\n            nn.Linear(lstm_hidden * 2, time_feature_count),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(time_feature_count, number_class_symbols)\n        )\n\n    def forward(self, x):\n        x = self.feature_extractor(x)\n        b, c, h, w = x.size()\n        x = x.view(b, c * h, w)\n        x = self.avg_pool(x)\n        x = x.transpose(1, 2)\n        x = self.bilstm(x)\n        x = self.classifier(x)\n        x = nn.functional.log_softmax(x, dim=2).permute(1, 0, 2)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.873824Z","iopub.execute_input":"2022-12-13T15:18:14.874214Z","iopub.status.idle":"2022-12-13T15:18:14.896432Z","shell.execute_reply.started":"2022-12-13T15:18:14.874183Z","shell.execute_reply":"2022-12-13T15:18:14.895352Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Define accuracy metric for evaluate validation dataset","metadata":{}},{"cell_type":"code","source":"class AverageMeter:\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef get_accuracy(y_true, y_pred):\n    scores = []\n    for true, pred in zip(y_true, y_pred):\n        scores.append(true == pred)\n    avg_score = np.mean(scores)\n    return avg_score","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.897836Z","iopub.execute_input":"2022-12-13T15:18:14.898191Z","iopub.status.idle":"2022-12-13T15:18:14.912755Z","shell.execute_reply.started":"2022-12-13T15:18:14.898165Z","shell.execute_reply":"2022-12-13T15:18:14.911664Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Training loop","metadata":{}},{"cell_type":"code","source":"import pickle as pkl\n\ndef safe(obj, filename):\n    with open(filename, 'wb') as outp:\n        pkl.dump(obj, outp)\n        \ndef read(filename):\n    with open(filename, 'rb') as inp:\n        return pkl.load(inp)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.914378Z","iopub.execute_input":"2022-12-13T15:18:14.914785Z","iopub.status.idle":"2022-12-13T15:18:14.922111Z","shell.execute_reply.started":"2022-12-13T15:18:14.914744Z","shell.execute_reply":"2022-12-13T15:18:14.921401Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if type(m) in [nn.Linear, nn.Conv2d, nn.Conv1d]:\n        torch.nn.init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            m.bias.data.fill_(0.01)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.923016Z","iopub.execute_input":"2022-12-13T15:18:14.923336Z","iopub.status.idle":"2022-12-13T15:18:14.937484Z","shell.execute_reply.started":"2022-12-13T15:18:14.923310Z","shell.execute_reply":"2022-12-13T15:18:14.936472Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def val_loop(data_loader, model, tokenizer, device):\n    model.eval()\n    acc_avg = AverageMeter()\n    for images, enc_texts, texts in data_loader:\n        batch_size = len(texts)\n        text_preds = predict(images, model, tokenizer, device)\n        acc_avg.update(get_accuracy(texts, text_preds), batch_size)\n    print(f'Validation, acc: {acc_avg.avg:.4f}')\n    return acc_avg.avg\n\ndef predict(images, model, tokenizer, device):\n    model.eval()\n    images = images.to(device)\n    with torch.no_grad():\n        output = model(images)\n    pred = torch.argmax(output.detach().cpu(), -1).permute(1, 0).numpy()\n    text_preds = tokenizer.decode(pred)\n    return text_preds\n\ndef train_loop(data_loader, model, criterion, optimizer, epoch):\n    loss_avg = AverageMeter()\n    model.train()\n    for images, enc_texts, texts in data_loader:\n        model.zero_grad()\n        images = images.to(device)\n        batch_size = len(texts)\n        output = model(images)\n        output_lenghts = torch.full(\n            size=(output.size(1),),\n            fill_value=output.size(0),\n            dtype=torch.long\n        )\n        text_lens = torch.LongTensor([len(text) for text in texts])\n        loss = criterion(output, enc_texts, output_lenghts, text_lens)\n        loss_avg.update(loss.item(), batch_size)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n        optimizer.step()\n    for param_group in optimizer.param_groups:\n        lr = param_group['lr']\n    print(f'\\nEpoch {epoch}, Loss: {loss_avg.avg:.5f}, LR: {lr:.7f}')\n    return loss_avg.avg\n\ndef train(dataloader, epochs):\n    train_loader, val_loader = dataloader['train'], dataloader['valid']\n    model = CRNN(number_class_symbols=tokenizer.get_num_chars())\n    model.apply(weights_init)\n    model.to(device)\n\n    criterion = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=True)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001,\n                                  weight_decay=0.01)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer=optimizer, mode='max', factor=0.5, patience=15)\n    best_acc = -np.inf\n    acc_avg = val_loop(val_loader, model, tokenizer, device)\n    for epoch in range(epochs):\n        loss_avg = train_loop(train_loader, model, criterion, optimizer, epoch)\n        acc_avg = val_loop(val_loader, model, tokenizer, device)\n        scheduler.step(acc_avg)\n        if acc_avg > best_acc:\n            best_acc = acc_avg\n        safe(model, f'model_{epoch}')","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:18:14.938961Z","iopub.execute_input":"2022-12-13T15:18:14.939283Z","iopub.status.idle":"2022-12-13T15:18:14.955849Z","shell.execute_reply.started":"2022-12-13T15:18:14.939258Z","shell.execute_reply":"2022-12-13T15:18:14.954833Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train(dataloader, 10)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T14:52:56.662865Z","iopub.execute_input":"2022-12-13T14:52:56.663386Z","iopub.status.idle":"2022-12-13T14:53:05.779643Z","shell.execute_reply.started":"2022-12-13T14:52:56.663351Z","shell.execute_reply":"2022-12-13T14:53:05.778025Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3797013276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_27/1291387818.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, epochs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         optimizer=optimizer, mode='max', factor=0.5, patience=15)\n\u001b[1;32m     54\u001b[0m     \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0macc_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mloss_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/1291387818.py\u001b[0m in \u001b[0;36mval_loop\u001b[0;34m(data_loader, model, tokenizer, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtext_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0macc_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Validation, acc: {acc_avg.avg:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/1291387818.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(images, model, tokenizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtext_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/3154904565.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbilstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/3154904565.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 762\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"img, enc_label, label = dataset_full[2001]","metadata":{"execution":{"iopub.status.busy":"2022-12-13T14:58:23.456830Z","iopub.execute_input":"2022-12-13T14:58:23.457249Z","iopub.status.idle":"2022-12-13T14:58:23.471091Z","shell.execute_reply.started":"2022-12-13T14:58:23.457216Z","shell.execute_reply":"2022-12-13T14:58:23.470183Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"pred = predict(img.unsqueeze(0).to(device), model, tokenizer, device)\npred","metadata":{"execution":{"iopub.status.busy":"2022-12-13T14:58:24.471474Z","iopub.execute_input":"2022-12-13T14:58:24.471905Z","iopub.status.idle":"2022-12-13T14:58:24.653977Z","shell.execute_reply.started":"2022-12-13T14:58:24.471851Z","shell.execute_reply":"2022-12-13T14:58:24.652837Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"['9']"},"metadata":{}}]},{"cell_type":"code","source":"real_img = torchvision.transforms.ToPILImage()(img)\nreal_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compute metrics","metadata":{}},{"cell_type":"code","source":"from evaluate import load\ncer = load(\"cer\")","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:17:41.364381Z","iopub.execute_input":"2022-12-13T15:17:41.364921Z","iopub.status.idle":"2022-12-13T15:17:52.667599Z","shell.execute_reply.started":"2022-12-13T15:17:41.364784Z","shell.execute_reply":"2022-12-13T15:17:52.666217Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a836ff1810433cb6f5102f65ebe24a"}},"metadata":{}}]},{"cell_type":"code","source":"model = CRNN(number_class_symbols=tokenizer.get_num_chars())\nreferences = dataset_test.labels","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:27:25.935951Z","iopub.execute_input":"2022-12-13T15:27:25.936443Z","iopub.status.idle":"2022-12-13T15:27:26.327020Z","shell.execute_reply.started":"2022-12-13T15:27:25.936407Z","shell.execute_reply":"2022-12-13T15:27:26.325915Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor img, enc_text, text in dataloader_test:\n    predictions += predict(img, model, tokenizer, device)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:27:27.116649Z","iopub.execute_input":"2022-12-13T15:27:27.117773Z","iopub.status.idle":"2022-12-13T15:38:30.035073Z","shell.execute_reply.started":"2022-12-13T15:27:27.117713Z","shell.execute_reply":"2022-12-13T15:38:30.033944Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"cer_score = cer.compute(predictions=references, references=references)\nprint(cer_score)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T15:39:52.395227Z","iopub.execute_input":"2022-12-13T15:39:52.396579Z","iopub.status.idle":"2022-12-13T15:39:52.771250Z","shell.execute_reply.started":"2022-12-13T15:39:52.396528Z","shell.execute_reply":"2022-12-13T15:39:52.770382Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}